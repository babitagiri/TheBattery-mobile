{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10f4f9a-4aca-49b6-affc-c89f0ccb87d7",
   "metadata": {},
   "source": [
    "# PCA Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35df8e91-c785-4e2a-bfd4-b1df8d1e2872",
   "metadata": {},
   "source": [
    "Putting some raw code examples from last quarter and from online regarding PCA. We got 3 options to try. I am leaning towards Option 3, but we should try all the options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a907fb-10f2-4a1a-8ccd-5b3b2762c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167918d3-4a8c-4462-86fd-46bc179d4adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImport cleaned data here.\\n\\nHopefully in some format like this but in specific terms.\\n\\n#reading the \"features\" csv\\nfeatures=pd.read_csv(\\'features.csv\\')\\nfeatures.head()\\n\\n#reading the \"target\" csv\\ntarget=pd.read_csv(\\'target.csv\\')\\ntarget.head\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import cleaned data here.\n",
    "\n",
    "Hopefully in some format like this but in specific terms.\n",
    "\n",
    "#reading the \"features\" csv\n",
    "features=pd.read_csv('features.csv')\n",
    "features.head()\n",
    "\n",
    "#reading the \"target\" csv\n",
    "target=pd.read_csv('target.csv')\n",
    "target.head\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ec7ae-65d4-45e7-a17b-382a18417c22",
   "metadata": {},
   "source": [
    "## OPTION 1. Our Code from Final Project\n",
    "Pretty much just ripping our code from the final project in using PCA analysis and right before we applied K-Means clustering. Not sure how effective this method is or exacly what we were doing or if it was even correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a3110-c35c-4a48-bb00-a1be5b1d7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a PCA instance: pca\n",
    "pca = PCA(n_components=2) #choose 8 because there 8 columns\n",
    "#Fit the PCA instance to the scaled data\n",
    "pca.fit(combdata)\n",
    "#Transform the scaled data: pca_features\n",
    "x_pca = pca.transform(combdata)\n",
    "#Print the shape of pca_features\n",
    "print(x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb0d1f-a744-4691-bb43-b9a3e93b96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame from the PCA results\n",
    "pca_df = pd.DataFrame(data = x_pca, columns = ['PC1', 'PC2'])\n",
    "#Add the target variable to this dataframe\n",
    "pca_df['Type of Material'] = combdata['Type of Material']\n",
    "#Plot the first two principal components\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Type of Material', data=pca_df, palette=['m', 'y', 'g'], alpha=0.6, s=100)\n",
    "plt.title('PCA on Scaled Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c0c32-8e30-463c-9f36-75bd0e9604f2",
   "metadata": {},
   "source": [
    "## OPTION 2: Code from online that kind of does what we want\n",
    "We probably want to do a feature importance after we find out which PC creates the largest variance. Putting a code from the internet that is similar to what we should want.\n",
    "https://stackoverflow.com/questions/50796024/feature-variable-importance-after-a-pca-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfad93-6d38-48af-b2cd-c5bedfddb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#In general a good idea is to scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)    \n",
    "\n",
    "pca = PCA()\n",
    "x_new = pca.fit_transform(X)\n",
    "\n",
    "def myplot(score,coeff,labels=None):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "    scalex = 1.0/(xs.max() - xs.min())\n",
    "    scaley = 1.0/(ys.max() - ys.min())\n",
    "    plt.scatter(xs * scalex,ys * scaley, c = y)\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlabel(\"PC{}\".format(1))\n",
    "plt.ylabel(\"PC{}\".format(2))\n",
    "plt.grid()\n",
    "\n",
    "#Call the function. Use only the 2 PCs.\n",
    "myplot(x_new[:,0:2],np.transpose(pca.components_[0:2, :]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa965fb-5643-49d2-9249-1b85abfb02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_\n",
    "[0.72770452, 0.23030523, 0.03683832, 0.00515193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089ec27-7aee-4162-b5fd-2ac914235db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs( pca.components_ ))\n",
    "\n",
    "[[0.52237162 0.26335492 0.58125401 0.56561105]\n",
    " [0.37231836 0.92555649 0.02109478 0.06541577]\n",
    " [0.72101681 0.24203288 0.14089226 0.6338014 ]\n",
    " [0.26199559 0.12413481 0.80115427 0.52354627]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edd88a-2417-491a-b86b-85ca5824ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(n_components=2).fit(train_features)\n",
    "X_pc = model.transform(train_features)\n",
    "\n",
    "# number of components\n",
    "n_pcs= model.components_.shape[0]\n",
    "\n",
    "# get the index of the most important feature on EACH component\n",
    "# LIST COMPREHENSION HERE\n",
    "most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "\n",
    "initial_feature_names = ['a','b','c','d','e']\n",
    "# get the names\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "# LIST COMPREHENSION HERE AGAIN\n",
    "dic = {'PC{}'.format(i): most_important_names[i] for i in range(n_pcs)}\n",
    "\n",
    "# build the dataframe\n",
    "df = pd.DataFrame(dic.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec46568-7e08-4bd5-a17e-8c0dc2cd8f46",
   "metadata": {},
   "source": [
    "## OPTION 3: Code from Dr. Sachi's Analysis mixed with our code \n",
    "Here is some code from Sachi, Lecture 20 plus our code from HW6. Pretty much Sachi trained a model with the PCA completed and then with the Random Forest, using a feature importance to find the most important feature. * This is the option I really want to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee17756-ffca-4fc4-bb92-1c4f81c7ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "from sklearn.decomposition import PCA \n",
    "# keep the first two components of the data \n",
    "pca = PCA (n_components=2)\n",
    "# fit the PCA model to the scaled data \n",
    "pca.fit(scaled_df_standard)\n",
    "x_pca = pca.transform(scaled_df_standard)\n",
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ab48b-0183-43f6-b963-d574a8dedb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "scatter=plt.scatter(x_pca[:,0],x_pca[:,1],c =cancer.target)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=cancer.target_names.tolist(), title=\"diagnoses\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49722a05-6a29-4a5b-beea-0d0ca8b08795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test \n",
    "X_train, X_test , y_train, y_test = train_test_split(cancer_df, cancer.target, test_size=0.20,random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630657a-a8db-4eda-bb9c-6f275c238ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying PCA on the training data \n",
    "pca = PCA(n_components=4)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e3f00-c3f7-4b86-9afd-47449d9e0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "scatter=plt.scatter(X_train_pca[:,0],X_train_pca[:,1],c =y_train)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=cancer.target_names.tolist(), title=\"diagnoses\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf6b84-9187-4363-9f57-22dbd10df6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a3471-afbf-4877-b858-31f0299a2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "RF_clf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98307d-1cd5-4a8b-bac7-fc819a8a04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(RF_clf.score(X_train_pca, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(RF_clf.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15da08-2c5d-4980-9da3-efefe089bbf6",
   "metadata": {},
   "source": [
    "And with that Random Forest Classifier, adding my own code to find Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d828c73-74c1-4ec9-9446-af7997990e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = RF_clf.feature_importances_\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea1ea8-1cf3-47e6-a101-aa29a2bfefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the feature importance \n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "print(feature_importances_df.sort_values(by='Importance', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
